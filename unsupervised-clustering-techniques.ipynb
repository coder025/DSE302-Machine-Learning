{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unsupervised Clustering Techniques","metadata":{"id":"7noVov4Uht5_"}},{"cell_type":"markdown","source":"## SAMBHAV AGRAWAL 19264 DATA SCIENCE AND ENGINEERING","metadata":{"id":"jTZCgKuFmSBF"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import DBSCAN","metadata":{"id":"Qr8yH05-tr9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/content/data.csv', header = None)\ndf.columns = ['Feature1', 'Feature2']\n\ndf","metadata":{"id":"5usgN2-bt7yo","outputId":"e8cedc10-ae0c-472f-d2fc-de118302e03d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,6))\n\nax = sns.scatterplot(data = df, x = 'Feature1', y = 'Feature2', s = 20)\nax.set_title('Points to be Clustered')","metadata":{"id":"CkzNIQvwuH4W","outputId":"39cf04e7-7363-4553-85c9-db02e1c35901"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of clusters is 2. (as given in the question)  But if we did not have the information about number of clusters, we could use Elbow plot to find number of clusters","metadata":{"id":"gvUEjrSPOy2w"}},{"cell_type":"code","source":"scaler = StandardScaler()\n\ndfs = scaler.fit_transform(df[['Feature1','Feature2']])\n\ndfs = pd.DataFrame(dfs)\n\ndfs.columns = ['Feature1','Feature2']\n\ndfs.head()","metadata":{"id":"EcjUIzHfUrHJ","outputId":"e2b28bad-ef04-4a38-8ad1-6bb9ad9f0213"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nclusters = []\n\nfor i in range(1, 11):\n    km = KMeans(n_clusters=i).fit(df)\n    clusters.append(km.inertia_)\n    \nfig, ax = plt.subplots(figsize=(12, 8))\nsns.lineplot(x=list(range(1, 11)), y=clusters, ax=ax)\nax.set_title('Searching for Elbow')\nax.set_xlabel('Clusters')\nax.set_ylabel('Inertia')\n\n# Annotate arrow\nax.annotate('Possible Elbow Point', xy=(3, 14), xytext=(3, 5), xycoords='data',          \n             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n\nax.annotate('Possible Elbow Point', xy=(5, 8), xytext=(5, 15), xycoords='data',          \n             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2))\n\nplt.show()","metadata":{"id":"n4m8Mv_XPjVg","outputId":"2989f4ff-90fb-4f2f-fe24-9ae261f6344a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Different Types of Clustering Techniques","metadata":{"id":"n9dfiG8f0Yl1"}},{"cell_type":"markdown","source":"## 1) Spectral Clustering","metadata":{"id":"2hL8CftS0ic0"}},{"cell_type":"code","source":"from sklearn.cluster import SpectralClustering, KMeans\n\nkm = KMeans(n_clusters = 2)\nkm.fit(df)\n\nplt.scatter(df['Feature1'], df['Feature2'], c = km.predict(df))","metadata":{"id":"aQFQCpDg0MUA","outputId":"650bd9a3-1aac-41c5-bab5-9d291f2b8fef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clustering = SpectralClustering(n_clusters=2, assign_labels='discretize',\n                                eigen_solver = 'lobpcg')\nclustering.fit(df)\n\nplt.scatter(df['Feature1'], df['Feature2'], c = km.predict(df))","metadata":{"id":"phTop-rha_lS","outputId":"dd57b520-377f-42e3-b3e5-21374fe6e0eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clustering = SpectralClustering(n_clusters=2, assign_labels='discretize',\n                                eigen_solver = 'arpack')\nclustering.fit(df)\n\nplt.scatter(df['Feature1'], df['Feature2'], c = km.predict(df))","metadata":{"id":"dffalDAabsgc","outputId":"b68b66e9-6592-44f3-c34d-2bac7e3e4c6a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Hierarchical (Agglomerative) Clustering\n","metadata":{"id":"5-SgD2yiUATe"}},{"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\nclusters_Agglomerative = AgglomerativeClustering(n_clusters=2,affinity = 'euclidean' ,\n                            linkage='ward').fit_predict(dfs)\n","metadata":{"id":"SPhHYsQpUITO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(dfs['Feature1'], dfs['Feature2'], c=clusters_Agglomerative, s=60)\n\nplt.show()","metadata":{"id":"iBtaV4jSWINp","outputId":"00b54ee0-17da-44f9-dfd8-07855958e48b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tuning the Parameters","metadata":{"id":"EW2D5bVEYmkM"}},{"cell_type":"code","source":"clusters_Agglomerative = AgglomerativeClustering(n_clusters=2,affinity = 'l1' ,\n                            linkage='complete').fit_predict(df)\n","metadata":{"id":"IIFBYNyOYrCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(dfs['Feature1'], dfs['Feature2'], c=clusters_Agglomerative, s=60)\n\nplt.show()","metadata":{"id":"7zlZqfPhY1rQ","outputId":"c00b4d58-f054-4cc0-9e4c-a9aff1dcca4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clusters_Agglomerative = AgglomerativeClustering(n_clusters=2,affinity = 'l1' ,\n                            linkage='average').fit_predict(df)\n","metadata":{"id":"1aFSBq4mZCRp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(dfs['Feature1'], dfs['Feature2'], c=clusters_Agglomerative, s=60)\n\nplt.show()","metadata":{"id":"8AIHqQKnZGrd","outputId":"987ab309-0cfa-4fd5-fb3f-fed4237cbec1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) DBSCAN","metadata":{"id":"oSSvM_GrW_pW"}},{"cell_type":"code","source":"db = DBSCAN(eps = 0.3088, min_samples = 81).fit(dfs)\n\nlabels = db.labels_\n\nprint('Labels:', np.unique(labels), '\\n')\n\nprint('Outliers:', labels.tolist().count(-1), '\\n')\n\nfig, ax = plt.subplots(figsize = (10,6))\n\nplt.title('Clusters')\n\nsns.scatterplot(dfs.Feature1,dfs.Feature2, hue = [f'cluster : {i}' for i in labels])\n\nplt.show()","metadata":{"id":"Ih_oSEOkXBdo","outputId":"faa51eeb-9eaf-4d42-eecf-6e7954e63939"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here the green colored dots is containing the noise","metadata":{"id":"OHncc2p0ZVAt"}},{"cell_type":"markdown","source":"## kDistance Graph","metadata":{"id":"PCJY7U57YS4B"}},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\nneigh = NearestNeighbors(n_neighbors=2)\nnbrs = neigh.fit(dfs[['Feature1','Feature2']])\ndistances, indices = nbrs.kneighbors(df[['Feature1','Feature2']])\n\n# The distance variable contains an array of distances between a data point and \n# its nearest data point for all data points in the dataset.\n\n# Letâ€™s plot our K-distance graph and find the value of epsilon. Use the following syntax:\n\n# Plotting K-distance Graph\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\nplt.figure(figsize=(8,4))\nplt.plot(distances)\nplt.title('K-distance Graph',fontsize=10)\nplt.xlabel('Data Points sorted by distance',fontsize=10)\nplt.ylabel('Epsilon',fontsize=10)\nplt.show()","metadata":{"id":"fnkzJZDvYO1N","outputId":"92aa2f4b-9993-435d-8ed6-66c65aea53b1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) kMeans","metadata":{"id":"WykZa6vWO4DE"}},{"cell_type":"code","source":"kms = KMeans(n_clusters=8, random_state=1).fit(df[['Feature1', 'Feature2']])\ndf['Cluster'] = kms.labels_\n\ndf","metadata":{"id":"KsKjjkdJdHMX","outputId":"1afeb9d5-ea99-4c14-996b-971795582db5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\nax = sns.scatterplot(data=df, x=\"Feature1\", y=\"Feature2\", hue='Cluster', \n                     s=20,  legend=True, palette='tab10')\n\n\nplt.legend(loc='lower right', title='Cluster')\nax.set_title(\"Final Clustered Points\")","metadata":{"id":"srOHZslKdUHY","outputId":"005c641e-8ae6-4609-ffbf-f010024e7306"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = df  \n\n\nnew_df['Cluster'] = new_df['Cluster'].replace([7],8)\nnew_df['Cluster'] = new_df['Cluster'].replace([2],8)\nnew_df['Cluster'] = new_df['Cluster'].replace([5],8)\nnew_df['Cluster'] = new_df['Cluster'].replace([3],8)\n\nnew_df['Cluster'] = new_df['Cluster'].replace([0],9)\nnew_df['Cluster'] = new_df['Cluster'].replace([1],9)\nnew_df['Cluster'] = new_df['Cluster'].replace([4],9)\nnew_df['Cluster'] = new_df['Cluster'].replace([6],9)\n\nnew_df['Cluster'] = new_df['Cluster'].replace([8],0)\n\nnew_df['Cluster'] = new_df['Cluster'].replace([9],1)","metadata":{"id":"gfezZIVydaOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(10, 6))\n\nax = sns.scatterplot(data=new_df, x=\"Feature1\", y=\"Feature2\", hue='Cluster', \n                     s=20,  legend=True, palette='tab10')\n\n\n\nplt.legend(loc='lower right', title='Clusters')\nax.set_title(\"Clustered Points for n_clusters equal to 8\")","metadata":{"id":"9WhEKEjid1Sh","outputId":"48f25c2d-7a4e-4fbc-e7c4-843be1d445c5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['Cluster'].mean()","metadata":{"id":"EX_uGapOeO6G","outputId":"70968237-9530-495a-ef2e-1318caae3979"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['Cluster'].to_csv(\"labels.csv\",header = None,index = None)\n\n","metadata":{"id":"Idxjs2CvgDmu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_t=pd.read_csv(\"labels.txt\",header=None)\ndf_t","metadata":{"id":"FEn5mchYgIcH","outputId":"49183874-517e-45ad-bf4f-fe90934ed9ce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_t.mean()","metadata":{"id":"UN_xoLCDgLEQ","outputId":"e8193995-e2d9-4690-e885-1dd3f3d56635"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kms = KMeans(n_clusters=10, random_state=1).fit(df[['Feature1', 'Feature2']])\ndf['Cluster'] = kms.labels_\n\ndf","metadata":{"id":"mbgBGLXXulRL","outputId":"72de0a3b-1994-42cf-da86-5f0c8116c811"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\nax = sns.scatterplot(data=df, x=\"Feature1\", y=\"Feature2\", hue='Cluster', \n                     s=20,  legend=True, palette='tab10')\n\n\nplt.legend(loc='lower right', title='Cluster')\nax.set_title(\"Final Clustered Points\")","metadata":{"id":"y9QxPeFEu7Mg","outputId":"39e1afa7-9885-4bd5-8973-07aef545122b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = df  \n\n\nnew_df['Cluster'] = new_df['Cluster'].replace([4],10)\nnew_df['Cluster'] = new_df['Cluster'].replace([9],10)\nnew_df['Cluster'] = new_df['Cluster'].replace([6],10)\nnew_df['Cluster'] = new_df['Cluster'].replace([8],10)\nnew_df['Cluster'] = new_df['Cluster'].replace([2],10)\n\nnew_df['Cluster'] = new_df['Cluster'].replace([0],1)\nnew_df['Cluster'] = new_df['Cluster'].replace([1],1)\nnew_df['Cluster'] = new_df['Cluster'].replace([7],1)\nnew_df['Cluster'] = new_df['Cluster'].replace([3],1)\nnew_df['Cluster'] = new_df['Cluster'].replace([5],1)\n\nnew_df['Cluster'] = new_df['Cluster'].replace([10],0)","metadata":{"id":"cncOMSPbvRJq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.head()","metadata":{"id":"5RJsZGehvbBx","outputId":"96ff6a29-b079-4ed8-e275-aeeaf0023a23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(10, 6))\n\nax = sns.scatterplot(data=new_df, x=\"Feature1\", y=\"Feature2\", hue='Cluster', \n                     s=20,  legend=True, palette='tab10')\n\n\n\nplt.legend(loc='lower right', title='Clusters')\nax.set_title(\"Clustered Points\")","metadata":{"id":"dRMq5eVRveBY","outputId":"e89cd54f-c505-4d33-f984-bb7ad2f72cef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df['Cluster'].mean()","metadata":{"id":"6KFqDQlhfNlH","outputId":"dcaddfd2-25bf-48d0-f96a-910dc1bbdeae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that by using kMeans, we are able to separate the 2 clusters given. ","metadata":{"id":"jMdvfNlfai5g"}},{"cell_type":"code","source":"new_df['Cluster'].to_csv(\"labels.txt\",index = None)","metadata":{"id":"pDHqc1yqRTwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_t=pd.read_csv(\"labels.txt\",header=None)\ndf_t.shape","metadata":{"id":"x0k-Ht3SRkza","outputId":"d89d7c1b-16a9-45ba-a0c0-989a33fab227"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For a complete 50-50 distribution in the points in the cluster it should average out to 0.5 because 1500 points are in each of the clusters and our is very close to 50% that is 0.51 approx.","metadata":{"id":"q-6Z_SescrFX"}},{"cell_type":"markdown","source":"## We got mean of the cluster label values as follows:\n\nFor n_clusters = 8 in kMeans Mean came out to be 0.5063333333333333 \nFor n_clusters = 10 in kMeans Mean came out to be 0.5136666666666667\n\nSince for n = 8 the value is more closer to half , so the kMeans performs better with value of n_clusters = 8","metadata":{"id":"D6QsS5VxfSSc"}},{"cell_type":"markdown","source":"## I already saved the labels file above for kMeans with n_clusters = 8.","metadata":{"id":"aAJe37P8gUxx"}},{"cell_type":"code","source":"df_t.head()","metadata":{"id":"CHhE_hmfeUip","outputId":"e5ea5c42-1636-45fb-fffc-5194799d01ee"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_t.describe()","metadata":{"id":"1AaXZlcIggqI","outputId":"d1756898-4d63-4475-826b-6205d35c968c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Nnxy7KzRgiI_"},"execution_count":null,"outputs":[]}]}